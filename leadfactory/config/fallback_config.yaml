# LLM Fallback Configuration
# This file defines the fallback behavior, cost thresholds, and provider settings

# Provider Configuration
providers:
  primary:
    name: "GPT-4o"
    type: "openai"
    model: "gpt-4o"
    api_key_env: "OPENAI_API_KEY"
    base_url: "https://api.openai.com/v1"  # pragma: allowlist secret
    timeout: 30
    max_retries: 3
    retry_delay: 1.0

  secondary:
    name: "Claude"
    type: "anthropic"
    model: "claude-3-sonnet-20240229"
    api_key_env: "ANTHROPIC_API_KEY"
    base_url: "https://api.anthropic.com"  # pragma: allowlist secret
    timeout: 30
    max_retries: 2
    retry_delay: 2.0

# Fallback Strategy Configuration
fallback:
  strategy: "cost_optimized"  # Options: retry, round_robin, cost_optimized
  max_attempts: 5
  circuit_breaker:
    failure_threshold: 5
    recovery_timeout: 300  # 5 minutes
    half_open_max_calls: 3

  # Conditions that trigger fallback
  triggers:
    - "rate_limit"
    - "cost_threshold_exceeded"
    - "timeout"
    - "server_error"
    - "quota_exceeded"
    - "model_unavailable"

# Cost Monitoring Configuration
cost_monitoring:
  enabled: true
  budget_limits:
    daily: 100.0
    monthly: 2000.0
    per_request: 5.0

  thresholds:
    warning: 0.8  # 80% of budget
    critical: 0.95  # 95% of budget
    fallback: 0.9  # 90% of budget triggers fallback

  cost_per_token:
    gpt-4o:
      input: 0.005  # per 1K tokens
      output: 0.015  # per 1K tokens
    claude-3-sonnet:
      input: 0.003  # per 1K tokens
      output: 0.015  # per 1K tokens

# Health Check Configuration
health_monitoring:
  enabled: true
  check_interval: 60  # seconds
  timeout: 10  # seconds
  response_time_threshold: 5.0  # seconds

  failure_thresholds:
    consecutive_failures: 3
    failure_rate: 0.5  # 50% failure rate
    slow_response_threshold: 2.0  # seconds

  alert_settings:
    enabled: true
    severity_levels:
      - "INFO"
      - "WARNING"
      - "ERROR"
      - "CRITICAL"

# Pipeline Integration Settings
pipeline:
  pause_on_all_failures: true
  pause_duration: 300  # 5 minutes
  graceful_degradation: true
  cache_responses: true
  cache_ttl: 3600  # 1 hour

  # Request optimization
  batching:
    enabled: false  # Disable for now, can enable later
    max_batch_size: 10
    batch_timeout: 5.0

  async_processing: true
  max_concurrent_requests: 10

# Environment-specific overrides
environments:
  development:
    cost_monitoring:
      budget_limits:
        daily: 10.0
        monthly: 100.0
        per_request: 1.0
    health_monitoring:
      check_interval: 30

  staging:
    cost_monitoring:
      budget_limits:
        daily: 50.0
        monthly: 500.0
        per_request: 2.0
    health_monitoring:
      check_interval: 45

  production:
    cost_monitoring:
      budget_limits:
        daily: 200.0
        monthly: 5000.0
        per_request: 10.0
    health_monitoring:
      check_interval: 60

# Logging Configuration
logging:
  level: "INFO"
  log_requests: true
  log_responses: false  # Don't log response content for privacy
  log_costs: true
  log_health_checks: true
  log_fallbacks: true
