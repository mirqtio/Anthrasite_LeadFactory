
| **City/State not saved** – Business address is stored as one string, with `city`/`state` fields left empty instead of parsed.                                                      | `leadfactory/pipeline/scrape.py`                                              | The Yelp scraping logic only joins the `display_address` into one string and captures ZIP; it never extracts city or state (both passed as blank to DB).                                                                                                                                                                       | **S**      | `json\n{\n "title": "Parse and Store City/State for Businesses",\n "description": "Extract city and state from business address and save to the `businesses`table instead of leaving them NULL. Update`create\_business` logic to parse address into city/state fields.",\n "tags": ["data", "parsing"],\n "estimate": "2 hours"\n}`                                                                                                                    |
| **Raw Yelp JSON retention decision** – No toggle or policy implemented for keeping vs. purging full API JSON responses (open issue in PRD).                                        | `leadfactory/pipeline/scrape.py`<br>`leadfactory/storage/postgres_storage.py` | The system currently always stores the raw Yelp/Google API JSON in the `businesses` record (passed into `create_business`), and no config or job purges it after use (privacy decision #1 from PRD remains unaddressed).                                                                                                       | **M**      | `json\n{\n "title": "Decide & Implement Yelp JSON Retention",\n "description": "Determine retention policy for raw Yelp/Google API JSON. If keeping, pass API response data into `businesses.yelp\_response\_json` (and document it); if purging, remove these fields and any related storage to avoid PII retention.",\n "tags": ["data", "privacy"],\n "estimate": "6 hours"\n}`                                                                      |
| **Screenshot generation (local)** – No local headless browser fallback for thumbnails; external API required.                                                                      | `leadfactory/pipeline/enrich.py`                                              | The code uses the ScreenshotOne API exclusively and only captures a screenshot if `SCREENSHOT_ONE_KEY` is set. There is no Playwright/Chromium usage for local captures, conflicting with the local-stack requirement (Mac Mini) in v1.0.                                                                                      | **M**      | `json\n{\n "title": "Implement Local Screenshot Capture",\n "description": "Add a Playwright (headless Chromium) fallback to capture full-page screenshots when `SCREENSHOT\_ONE\_KEY` is not provided, so the system can run fully on local hardware without external screenshot APIs.",\n "tags": ["screenshot", "headless", "local"],\n "estimate": "8 hours"\n}`                                                                                    |
| **Email thumbnail missing** – Outreach emails do not actually embed the website screenshot thumbnail as specified.                                                                 | `leadfactory/pipeline/email_queue.py`<br>`etc/email_template.html`            | The generated HTML for emails contains no `<img>` tag or content ID for a website thumbnail (the template had a `.mockup-container` placeholder not populated). Attachments for screenshot are prepared, but the email content never references the inline thumbnail, so recipients don’t see their current site preview.      | **M**      | `json\n{\n "title": "Embed Website Thumbnail in Email",\n "description": "Modify email content generation to include the screenshot thumbnail. Use the stored screenshot asset (embed as inline image with content-ID or via a public link) in the email HTML as a small preview of the site, per PRD.",\n "tags": ["email", "thumbnail", "HTML"],\n "estimate": "4 hours"\n}`                                                                          |
| **AI content vs. template** – GPT-generated email copy isn’t fully integrated into the standard template (CAN-SPAM footer, unsubscribe link).                                      | `leadfactory/pipeline/unified_gpt4o.py`<br>`leadfactory/email/templates.py`   | The Unified GPT-4o pipeline was constructing its own HTML body (subject line, intro, issues list, etc.) in code, bypassing the Jinja email template that includes our address and unsubscribe link. Although an AI personalization module exists, the final assembly still risks skipping the official template in some flows. | **M**      | `json\n{\n "title": "Integrate AI Content with Email Template",\n "description": "Use the Jinja EmailTemplateEngine to inject GPT-generated text (subject, intro, issues list, etc.) into the predefined HTML template that includes our CAN-SPAM footer and unsubscribe link. Ensure the final sent email consistently uses the unified template.",\n "tags": ["email", "template", "compliance"],\n "estimate": "8 hours"\n}`                         |
| **Bounce rate handling** – No automation to monitor hard bounce >2% or to warm up a new IP pool.                                                                                   | *SendGrid integration code*<br>`leadfactory/pipeline/email_queue.py`          | The system checks bounce rate on startup and aborts sending if the current pool’s rate exceeds 2%, but it doesn’t initiate any IP pool switch or warming workflow. The PRD task (#21) for automatically swapping to a dedicated pool and warming it up is not implemented.                                                     | **M**      | `json\n{\n "title": "Auto-Monitor Bounce Rate & IP Warmup",\n "description": "Implement periodic or pre-send checks on bounce rate (bounces/total emails). If >2%, log an alert and automatically switch the SendGrid IP pool from 'shared' to 'dedicated' (or trigger a warm-up sequence for a new IP). Include unit tests with fake bounce data to validate pool switching.",\n "tags": ["deliverability", "monitoring"],\n "estimate": "6 hours"\n}` |
| **Per-service cost caps** – Budget gating is not granular by API service (LLM vs. SEMrush daily spend).                                                                            | `leadfactory/config/settings.py`<br>`.env.example`                            | The config implements a global daily/monthly budget limit, but there are no environment vars for e.g. `MAX_DOLLARS_LLM` or `MAX_DOLLARS_SEMRUSH`. This means the system won’t halt or alert if one service (GPT-4 or SEMrush) exceeds its intended daily cost in isolation.                                                    | **M**      | `json\n{\n "title": "Enforce Per-Service Daily Cost Caps",\n "description": "Extend cost tracking to enforce daily spend limits for LLM and SEMrush usage. Introduce env vars (e.g. MAX_DOLLARS_LLM, MAX_DOLLARS_SEMRUSH); when usage exceeds these, disable or queue those API calls until next day and log alerts. Update docs and tests for budget enforcement.",\n "tags": ["cost", "monitoring"],\n "estimate": "6 hours"\n}`                      |
| **Nightly DB backup** – *No gap: implemented.* (The nightly process now includes `backup_postgres.sh` with pg\_dump and optional rsync to NAS, satisfying the backup requirement.) |                                                                               |


**Proposed Tasks:**

1. **Parse and Store City/State for Businesses** – Extract city and state from addresses before calling `create_business`, and persist them in the `businesses` table (currently left NULL). *(Estimate: 2 hours)*

2. **Decide & Implement Yelp JSON Retention** – Determine the policy for raw API JSON (Yelp/Google). If retaining, store the JSON in `businesses.yelp_response_json` (as done now) and document it; if not, remove those fields and avoid saving PII. *(Estimate: 6 hours)*

3. **Implement Local Screenshot Capture** – Add a Playwright (headless Chrome) fallback for screenshot generation when no `SCREENSHOT_ONE_KEY` is set, so the pipeline can capture site images on the Mac Mini without an external API. *(Estimate: 8 hours)*

4. **Embed Website Thumbnail in Email** – Modify the email assembly to embed the website screenshot thumbnail image. Ensure the HTML template includes an `<img>` tag (or content-ID reference) for the thumbnail so recipients see a preview of their current site in the outreach email. *(Estimate: 4 hours)*

5. **Integrate AI Content with Email Template** – Ensure GPT/AI-generated email content is inserted into the standard HTML template that contains our branding, physical address, and unsubscribe link. Use the existing Jinja EmailTemplateEngine to merge AI text into the template instead of constructing raw HTML in code. *(Estimate: 8 hours)*

6. **Auto-Monitor Bounce Rate & IP Warmup** – Implement an automated deliverability monitor: if the 7-day bounce rate exceeds 2%, log an alert and switch sending to a “warm-up” IP pool or sub-user with lower volume until reputation recovers. This task includes updating configuration for multiple IP pools and writing a cron or pre-send check to trigger pool swapping. *(Estimate: 6 hours)*

7. **Enforce Per-Service Daily Cost Caps** – Extend the budget gating system to cap individual service usage. Add env settings like `MAX_DOLLARS_LLM` and `MAX_DOLLARS_SEMRUSH` and update the cost tracker to halt or pause calls to OpenAI or SEMrush APIs when their daily spend would exceed those limits. *(Estimate: 6 hours)*
